{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022a2832",
   "metadata": {},
   "source": [
    "# Causal Machine Learning for Treatment Effect Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9749f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "#from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# get standard models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sources.doubly_robust import doubly_robust\n",
    "from sources.models.TARNet import TARnetICFR\n",
    "from significance import *\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from auxiliary import data_processing, doubly_robust, visualise, visualise_ites, impute_missing_values_knn, run_model, undersample, full_contra_indications_tracker, value_based_contra_indications_tracker, period_decomposition, multicol\n",
    "from icodes import encoding\n",
    "\n",
    "# from datetime import timedelta\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bccc9",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The purpose of this notebook is to provide and end-to-end description of the treatment effect estimation process. This notebook consists of three parts:\n",
    "\n",
    "1. **Data processing**: The first part is the data processing part. Here we basically prepare the data for the ML models.\n",
    "2. **Causal ML Models**: The second part of the notebook consists of a series of causal ML learning models. In particular, we use the causal meta-learning framework. \n",
    "3. **Adadptive Model**: The third part of the notebook is also a machine learning model. However, contrary to the models before, this one was developed by the VU team and allows for more control over the estimation proces. \n",
    "\n",
    "Please find below an overview of the steps we will go through. Note that the boxes do not correspond one-to-one to sections in the notebook, but the general flow is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f80659",
   "metadata": {},
   "source": [
    "![alt text](images\\ModellingOverview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3702ec1",
   "metadata": {},
   "source": [
    "## 1.a. Preliminaries \\& Design Choices\n",
    "\n",
    "We first want to get some preliminaries out of the way. In particular, we would like to make some specific **design choices** explicit. Below, we can set the following parameters, thereby modifying specific choices:\n",
    "\n",
    "- ``EXPOSURE_THRESHOLD``: The treatment is binary. However, how much treatment is provided can be changed with this variable. In essence, it determines the cut-off value. For instance, we can set it to 60 minutes in the case of physical therapy (in mins.). Then, patients with more then 60 minutes of PT will be assigned T=1, those below will be T=0.\n",
    "- ``PERIOD_MIN``: Minimal time period between baseline measurement and followup measurement. N.B. If this is set too low, the effect may not yet register. Too high and the effect may have faded out. \n",
    "- ``PERIOD_MAX``: Maximal time period between baseline measurement and followup measurement. N.B. If this is set too low, effect may not yet register. Too high and the effect may have faded out.  \n",
    "- ``REMOVE_MULTI_COL``: Whether or not to remove multicollinear columns. \n",
    "- ``CORRELATION_THRESHOLD``: Threshold for removing collinear columns. \n",
    "- ``UNDERSAMPLE``: Some models perform better when undersampling the minority class. For instance, if there are 1000 cases of patients with PT (T=0) and only 150 with PT (T=1), setting this to ``True`` ensures that 150 patients are sampled from PT (T=0), resulting in 300 observations in total.\n",
    "- ``IMPUTE``: Whether or not to impute missing *covariate* values.\n",
    "- ``PROPENSITY``: Whether or not to add a propensity score to the model.\n",
    "- ``CLEAN_COMPARE``: By default (when this is set to ``False``), the data processing script assigns any observations below ``EXPOSURE_THRESHOLD`` to the control group and  any observation above ``EXPOSURE_THRESHOLD`` to treated. Setting this parameter to ``True`` creates a scenario where *only* observation that did not get any treatment are assigned to the control group. For instance, in the case of PT, we would have a control group of patients getting only 0 mins. of PT and a treated group of patients with, say, more than 60 mins. of PT.\n",
    "- ``TREATMENT``: Name of the treatment variable.\n",
    "- ``TARGET``: Name of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90862091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# set the exposure threshold for binary dichtomization. In the case of PT, 60 minutes of PT at least. \n",
    "EXPOSURE_THRESHOLD = 45#30 # SET TO 30\n",
    "\n",
    "# set the period between observations. We only consider the effects between 120 and 240 days after exposure. \n",
    "PERIOD_MIN = 20 # /MAYBE CHECK WITH 60? \n",
    "PERIOD_MAX = 190 # CHECK WITH 120 DAYS \n",
    "\n",
    "# if we want to move multicollinear columns, set to True\n",
    "REMOVE_MULTI_COL = True\n",
    "\n",
    "# set the threshold for multicollinearity drops \n",
    "CORRELATION_THRESHOLD = 0.6\n",
    "\n",
    "# set to True if we want to undersample\n",
    "UNDERSAMPLE = True #False #True\n",
    "\n",
    "# set to True if we want to impute missing values\n",
    "IMPUTE = True\n",
    "\n",
    "PROPENSITY = True\n",
    "\n",
    "# clean compare (to be used if only > threshold AND treatment = 0)\n",
    "CLEAN_COMPARE = True\n",
    "\n",
    "TREATMENT = 'in3eb' # (minutes or days of physical therapy)\n",
    "OUTCOME = 'sADLSF' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f092037",
   "metadata": {},
   "source": [
    "Having set the desired parameters, we will now read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ac00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/dutch_LTCF_all.csv\"\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f\"Treatment before processing {len(df[df[TREATMENT]>EXPOSURE_THRESHOLD])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for date\n",
    "df[['sDRS', 'ii1o']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c38f8",
   "metadata": {},
   "source": [
    "## Part 2. Data Processing\n",
    "\n",
    "In this first part, we will carry out the data processsing. In particular, we would like to select the relevant covariates, make a pre-selection based on patient characteristics (e.g. whether or not contra-indications are present), select the relevant period of observation, impute missing *coviariate* values and, lastly, handle any multi-collinearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdc92a",
   "metadata": {},
   "source": [
    "Next, we define the lists of covariates, clinical indications and contra-indications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDS -> ICODE\n",
    "# colname translation procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contra_indications = ['ij2e', 'ij2l', 'ij2n', 'ij2t', 'ij2q', 'ij2r', 'ij6b', 'ij6c',  'in6b', 'in6c'] \n",
    "\n",
    "#BIGGER THAN\n",
    "contra_indications = {'sCPS': [4, 5], 'in2a': [2,3],\n",
    "                                 'in2c': [2,3], 'in2e': [2,3], 'in2f': [2,3],\n",
    "                                 'in2g': [2,3], 'in2h':[2,3], 'in2i':[2,3],\n",
    "                                 'in2j':[2,3], \n",
    "                                  'ij2e': [1,2,3,4,5,6,7,8], 'ij2l': [1,2,3,4,5,6,7,8]\n",
    "                                 , 'ij2n': [1,2,3,4,5,6,7,8], 'ij2t': [1,2,3,4,5,6,7,8]\n",
    "                                 , 'ij2q': [1,2,3,4,5,6,7,8], 'ij2r': [1,2,3,4,5,6,7,8]\n",
    "                                 , 'ij6b': [1,2,3,4,5,6,7,8], 'ij6c': [1,2,3,4,5,6,7,8]\n",
    "                                 , 'in6b': [1,2,3,4,5,6,7,8,9], 'in6c': [1,2,3,4,5,6,7,8,9]}\n",
    "\n",
    "# also convert values to list for ease of processing later on\n",
    "#listed_val_based_ind = [key for key, value in value_based_contra_indications.items()]\n",
    "\n",
    "#contra_indications = contra_indications #+ listed_val_based_ind\n",
    "\n",
    "# list relevant confounders\n",
    "confounders = ['ik3',  'id4a', 'ie3e', 'ih1', \n",
    "                        'ih3', 'ih5', 'ij6a',  \n",
    "                        'il7', 'il1',  'sCPS', 'iA2', 'sAGE_cat']\n",
    "\n",
    "# list clinical indications\n",
    "clinical_indications = {'sDRS': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], 'ij1': [1,2,3,4,5,6,7,8], 'ij12': [1,2,3,4,5,6,7,8], \n",
    "                      'ij2a': [1,2,3,4,5,6,7,8], 'ij2b': [1,2,3,4,5,6,7,8], 'ij2c': [1,2,3,4,5,6,7,8], \n",
    "                      'ij2d': [1,2,3,4,5,6,7,8], 'sAGE_cat': [i for i in range(60, 85)]}\n",
    "   \n",
    "            \n",
    "# ADD VALUE BASED CLINICAL INDICATIONS, E.G. {'sDRS' : [3,4]}\n",
    "\n",
    "# list of other relevant variables\n",
    "relevant_vars = ['iA9', 'Clientid', TREATMENT, OUTCOME]\n",
    "\n",
    "print(len(contra_indications))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547c109",
   "metadata": {},
   "source": [
    "Please note that you can get the meaning of the icodes by running the ``encoding``-function below. You only need to change the name of the ``code`` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27880938",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'ie3e'\n",
    "print(encoding[(code).lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a19605",
   "metadata": {},
   "source": [
    "### 2.a. Indications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.Series(False, index = df.index)\n",
    "\n",
    "for column, good_values in clinical_indications.items():\n",
    "    mask |= df[column].isin(good_values)\n",
    "    \n",
    "df_included = df[mask]\n",
    "df = df_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f77f4",
   "metadata": {},
   "source": [
    "### 2a. Contra-indications\n",
    "\n",
    "Next, the first thing we want to do is to drop patients that have a contra-indication for the treatment in questions. In the code below, we specify the contra-indications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de53fd0",
   "metadata": {},
   "source": [
    "Finally, for some contra-indications we want to exclude based on particular values only. We can do this by running the script below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d930109",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, bad_values in contra_indications.items():\n",
    "    df = df[~df[column].isin(bad_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137c386",
   "metadata": {},
   "source": [
    "Having processed the contra-indications, we can now select the necessary columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[list(clinical_indications.keys())+confounders + relevant_vars + list(contra_indications.keys())]\n",
    "print(f\"Treatment after selecting covariates {len(df[df[TREATMENT]>=EXPOSURE_THRESHOLD])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df#[df['sDRS']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cdf9c",
   "metadata": {},
   "source": [
    "### 2.b. Baseline-Followup Selection\n",
    "\n",
    "Important to note here is that in this particular setup, our goal is to **estimate the outcome value at follow up from the covariates *and* outcome variable at baseline**. \n",
    "\n",
    "Below you find a schematic depiction of how we want to process the data. As you can see, there are two timelines:\n",
    "\n",
    "1. **Timeline 1**: Naturally processes from baseline to follow up over time, without any intervention in the meantme.\n",
    "2. **Timeline 2**: Same as before, but with the difference that not an intervention has take place at some point in time between baseline and follow up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c28d1",
   "metadata": {},
   "source": [
    "![alt text](TimelineModels.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f61916",
   "metadata": {},
   "source": [
    "Our goal is therefore to, *for each observation*, take the values (**pre-treatment** covariates, outcome on baseline $y_{t}$) of baseline, and the  values at follow up (outcome on follow up $y_{t+1}$) and store it in a convenient manner. Important to note is that as patient may have *several* of these baseline-followup recors where sometimes an intervention may have occured and sometimes not. We decided to do this to, again, safe as much data as possible. \n",
    "\n",
    "Let us begin by first counting the number of assesments. We do this, because it is not possible to include patients without followup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of assesments\n",
    "counter = lambda x: len(df[df['Clientid']==x])\n",
    "\n",
    "# count number of items\n",
    "df['num_assesments'] = df['Clientid'].apply(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2d9af",
   "metadata": {},
   "source": [
    "Let us select only observations with more than 2 assesments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of assesments higher than 1\n",
    "df = df[df['num_assesments']>=2]\n",
    "\n",
    "print(f'{len(df)} observations remaining.')\n",
    "print(f\"Treatment after selecting on number of assesments {len(df[df[TREATMENT]>EXPOSURE_THRESHOLD])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f30a38",
   "metadata": {},
   "source": [
    "In the code below, we want to process the data a bit further. First, we want to make sure that the date columns (``iA9``) is in the correct format. Then we want to order based on ID and date. Also, we want to drop missing dates (if there are any) and drop any duplicated observations. Lastly, we want to make sure that the outcome is in the right format (i.e. a ``float``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to datetime \n",
    "df['iA9'] = pd.to_datetime(df['iA9']) \n",
    "# sort values by ID and date\n",
    "df = df.sort_values(by = ['Clientid', 'iA9'])\n",
    "# drop nans on dates of assesment\n",
    "df = df[df['iA9'].isna()==False]\n",
    "# drop duplicated values\n",
    "df = df.drop_duplicates()\n",
    "df[OUTCOME] = df[OUTCOME].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43866522",
   "metadata": {},
   "source": [
    "### 2.c Drop Duplicated Values\n",
    "\n",
    "Next, because there may be two assesments on the same date, we also want to drop those (regardless of the reason as inspecting that is beyond the scope of this project notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Clientid' and then apply the duplicate check on 'iA9' within each group\n",
    "duplicated_indices = df.groupby('Clientid').apply(\n",
    "    lambda x: x[x['iA9'].duplicated()].index).explode()\n",
    "\n",
    "# Drop NaN values from the index list if they exist\n",
    "duplicated_indices = duplicated_indices.dropna()\n",
    "\n",
    "# Convert the result into a list if it's not empty\n",
    "if not duplicated_indices.empty:\n",
    "    duplicated_indices = duplicated_indices.tolist()\n",
    "\n",
    "    # Drop the duplicates using the list of indices\n",
    "    df = df.drop(index=duplicated_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32c7d6",
   "metadata": {},
   "source": [
    "### 2.d. Clean Compare\n",
    "If we want to only compare between those patients that receive either 0 treatment or a treatment above the threshold value, we run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68930d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_COMPARE:\n",
    "    df = df[(df[TREATMENT] <= 0) | (df[TREATMENT] >= EXPOSURE_THRESHOLD)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ddb34",
   "metadata": {},
   "source": [
    "### 2.e Period Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a67a3",
   "metadata": {},
   "source": [
    "The piece of code (i.e. the function ``period_decomposition``) below is a loop that basically does the following:\n",
    "\n",
    "1. Create a temporary dataframe ``temp_df``. We do this to make sure that there is an empty entity (i.e. data storage) to which we can append new, cleaned and processed observations.\n",
    "2. Then, for each patient we do the following:\n",
    "3. Look at all the observation dates.\n",
    "4. Select the target outcome at follow up and at baseline.\n",
    "5. Append each period to the ``temp_df`` *until running out of dates*. \n",
    "6. Move to the next patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e300f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_decomposition(df, target):\n",
    "    # List to store the rows of the new DataFrame\n",
    "    rows = []\n",
    "\n",
    "    # Unique client IDs\n",
    "    client_ids = df['Clientid'].unique()\n",
    "    total = len(client_ids)\n",
    "\n",
    "    for count, client_id in enumerate(client_ids, start=1):\n",
    "        # Inform the user about the progress\n",
    "        if count % 1000 == 0 or count == total:\n",
    "            print(f'{count} of {total} items completed...')\n",
    "\n",
    "        # Extract rows for the current client\n",
    "        client_rows = df[df['Clientid'] == client_id].sort_values('iA9')\n",
    "        client_dates = client_rows['iA9'].tolist()\n",
    "\n",
    "        for i in range(len(client_dates) - 1):\n",
    "            baseline_date = client_dates[i]\n",
    "            followup_date = client_dates[i + 1]\n",
    "\n",
    "            # Extract the rows for baseline and follow-up\n",
    "            baseline_row = client_rows[client_rows['iA9'] == baseline_date]\n",
    "            followup_row = client_rows[client_rows['iA9'] == followup_date]\n",
    "\n",
    "            # Calculate the outcomes\n",
    "            outcome_t0 = float(baseline_row[target])\n",
    "            outcome_t1 = float(followup_row[target])\n",
    "\n",
    "            # Prepare a new row with all necessary information\n",
    "            new_row = baseline_row.iloc[0].to_dict()\n",
    "            new_row['OutcomeT0'] = outcome_t0\n",
    "            new_row['OutcomeT1'] = outcome_t1\n",
    "            new_row['OutcomeT0Date'] = baseline_date\n",
    "            new_row['OutcomeT1Date'] = followup_date\n",
    "            rows.append(new_row)\n",
    "\n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    temp_df = pd.DataFrame(rows)\n",
    "    print(\"Completed.\")\n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa46020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = period_decomposition(df, target = OUTCOME)\n",
    "print(f\"Treatment after processing {len(df[df[TREATMENT]>EXPOSURE_THRESHOLD])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ffe04",
   "metadata": {},
   "source": [
    "### 2.f Dichotomize Treatment Variable\n",
    "\n",
    "Because our model can only deal with binary treatments, we need to convert the continuous treatments into binary ones. We will do that using a simple fuctions. Recall that the threshold has been set using the ``EXPOSURE_THRESHOLD`` variable above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = lambda x: 1 if x >= EXPOSURE_THRESHOLD else 0\n",
    "# convert treatment to binary\n",
    "df['treatment'] = df[TREATMENT].apply(binary)  \n",
    "df = df.drop(columns = [TREATMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5068ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing outcome or treatment \n",
    "df = df.dropna(subset = ['OutcomeT0', 'OutcomeT1', 'treatment'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6eb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffd723",
   "metadata": {},
   "source": [
    "### 2.g Select Relevant Period\n",
    "\n",
    "Because the base data is too crude (the time periods between follow-up and baseline may be too far apart), we want to select a suitable period between observations. In essence, we aim to select a time window which is, on the one hand, determined by the minimum time (``PERIOD_MIN``) between baseline measurement and follow-up measurement and the maximum of that time window (``PERIOD_MAX``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feba781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get difference between dates\n",
    "df['date_diff'] = df['OutcomeT1Date'] - df['OutcomeT0Date'] \n",
    "df['date_diff'] = df['date_diff'].dt.days \n",
    "\n",
    "# select relevant period\n",
    "df = df[df['date_diff'] <= PERIOD_MAX]\n",
    "df = df[df['date_diff'] >= PERIOD_MIN]\n",
    "\n",
    "df = df.drop(columns = ['OutcomeT1Date', 'OutcomeT0Date', 'date_diff', 'iA9', OUTCOME, 'Clientid'])\n",
    "# examine how many treatment observations are left\n",
    "len(df[df['treatment']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d5175",
   "metadata": {},
   "source": [
    "### 2.h Impute Missing Values\n",
    "\n",
    "In this part, we impute missing values. We use a standard KNN-imputer. If desired, it is possible to change the number of neighbours. Keep in mind that we can set this to ``False`` if we do not want to run it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fea014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing = IMPUTE\n",
    "if IMPUTE:\n",
    "    df = impute_missing_values_knn(df, n_neighbors=5)\n",
    "else:\n",
    "    df = df.dropna()\n",
    "    print(len(df[df['treatment']==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a768ca",
   "metadata": {},
   "source": [
    "### 2.i Handle Multicollinearity\n",
    "\n",
    "Here we will handle multi-collinear columns. Keep in mind that we can set this to ``False`` if we do not want to run it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7767c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_MULTI_COL:\n",
    "    df = multicol(df, CORRELATION_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01027c",
   "metadata": {},
   "source": [
    "### 2.j Handle Empty Columns\n",
    "\n",
    "In the process, it may be that we end up with columns that contain only $0$ values. We want to drop these columns, as they are not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6579421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop num_assesment column, not relevant anymore\n",
    "df = df.drop(columns = ['num_assesments'])\n",
    "# get a list of coviariate columns\n",
    "X = df.drop(columns = ['OutcomeT1', 'OutcomeT0', 'treatment']).columns\n",
    "\n",
    "# drop columns that only have 0 values\n",
    "for col in X:\n",
    "    if len(df[df[col]==0]) == len(df):\n",
    "        print(f\"{col} - {encoding[col.lower()]} dropped.\" )\n",
    "        df = df.drop(columns = [col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391772f0",
   "metadata": {},
   "source": [
    "### 2.k Store CSV\n",
    "\n",
    "In the last part of this notebook, we will store that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f99ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['OutcomeT1', 'OutcomeT0', 'treatment']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment = TREATMENT#'in3eb' # (minutes or days of physical therapy)\n",
    "# target = #'sADLSF' \n",
    "\n",
    "#df = df.drop(columns = 'num_assesments')\n",
    "df.to_csv(f\"data/05-07-2024-Dutch_LTCF_cleaned_data_with_selected_covar_{TREATMENT}-{OUTCOME}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5390d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD SKIP FOR TREATMENT AND OUTCOME T1\n",
    "covars = [str(i) for i in df.columns]\n",
    "covar_names = []\n",
    "\n",
    "#print(encoding[(code).lower()])\n",
    "\n",
    "for covar in covars:\n",
    "    if (covar != 'treatment') and (covar != 'OutcomeT1'):\n",
    "\n",
    "        try:\n",
    "            covar_names.append(encoding[(covar).lower()])\n",
    "        except:\n",
    "            covar_names.append(covar)\n",
    "            \n",
    "covar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85aa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD SKIP FOR TREATMENT AND OUTCOME T1\n",
    "covars = [str(i) for i in df.columns]\n",
    "covar_names = []\n",
    "\n",
    "#print(encoding[(code).lower()])\n",
    "\n",
    "for covar in covars:\n",
    "    if (covar != 'treatment') and (covar != 'OutcomeT1'):\n",
    "\n",
    "        try:\n",
    "            covar_names.append(covar)\n",
    "        except:\n",
    "            covar_names.append(covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee604d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e28108",
   "metadata": {},
   "source": [
    "### Note to Teams: Please Start Here\n",
    "\n",
    "**MAKE SURE THAT THE DATA IS IN THE EXACT FORMAT AS BELOW.**\n",
    "\n",
    "Checklist:\n",
    "\n",
    "1. The covariates must come first.\n",
    "2. Then, there must be the outcome at baseline called ``OutcomeT0``.\n",
    "3. There must be an outcome at followup called ``OutcomeT1``.\n",
    "4. You may have a propensity score columns (``ps``), but this is not required. Same for clusters.\n",
    "5. There must be a treatment column *at the end* called ``treatment``. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e493",
   "metadata": {},
   "source": [
    "## Part 3. Machine Learning\n",
    "\n",
    "Having processed the data, we can now move on the the machine learning (ML) part. Recall that we model using the meta-learning paradigm. Below is a schematic depiction of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21542a9",
   "metadata": {},
   "source": [
    "![alt text](images\\ModelGoal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e0980",
   "metadata": {},
   "source": [
    "As can be seen, for a given patient, we can - *after training* - provide the details of that patient. These details are the outcome at baseline (``OutcomeT0``), the covariates and whether or not we include treatment. This allows us to compute the **individual treatment effect** (ITE), the predicted effect unter treatment minus the predicted effect under control.\n",
    "\n",
    "However, before we are able to estimate the ITE for a patient, we need to train the model. In meta-learning we always train two models. The first model is trained on the control group and the second model is trained on the treated group. Let us now first state what the ``outcome`` and ``intervention`` variables are.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271a03a",
   "metadata": {},
   "source": [
    "![alt text](images\\GeneralPlotTrajectoryInterpretation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a4fab",
   "metadata": {},
   "source": [
    "Next, we want to select the models. Here we will use ``RandomForestRegressor()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = RandomForestRegressor()\n",
    "model1 = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e795bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the Excel file\n",
    "excel_file = f'data/hyperparameters/model_hyperparameters_RandomForest.xlsx'\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "    # Get hyperparameters\n",
    "    hyperparameters = model.get_params()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([hyperparameters])\n",
    "\n",
    "    # Write each model's hyperparameters to a different sheet\n",
    "    df.to_excel(writer, sheet_name=\"RandomForest\")\n",
    "\n",
    "print(\"Hyperparameters of models have been saved to 'model_hyperparameters.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5363a98",
   "metadata": {},
   "source": [
    "Then, we want to retrieve the data. We can use the data from above, but here we will read the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45337bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call your data file here\n",
    "FILE = f\"data/03-10-2023-Dutch_LTCF_cleaned_data_with_selected_covar_{TREATMENT}-{OUTCOME}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(FILE)\n",
    "\n",
    "# all_data_control = all_data[all_data['treatment']==0]\n",
    "# all_data_control[(all_data_control['sAGE_cat']>=65) & (all_data_control['sAGE_cat']<= 74)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_treatment = all_data[all_data['treatment']==1]\n",
    "all_data_treatment[(all_data_treatment['sAGE_cat']>=65) & (all_data_treatment['sAGE_cat']<= 74)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data_treatment[all_data_treatment['ii1p']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac62fe",
   "metadata": {},
   "source": [
    "Afterwards, we can run the model. The only thing to do is to run the ``run_model``-function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = \"RandomForest\"\n",
    "\n",
    "metrics, predictions_t, predictions_c, y_test_t, y_test_c, ites_test, ites_train, X_test_t, X_test_c, X_train_c, X_train_t = run_model(n_bootstraps = 1, file = FILE, model0 = model0, model1 = model1, undersampled = UNDERSAMPLE, include_propensity = PROPENSITY, intervention = TREATMENT, outcome = OUTCOME, machine = \"RandomForest\", num_iter = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cada1e4",
   "metadata": {},
   "source": [
    "We can first compute the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8545312",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval(data=ites_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval(data=ites_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a813727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_mean = np.mean(ites_test)\n",
    "# stdev = np.std(ites_test, ddof=1)\n",
    "# n = len(ites_test)\n",
    "# degfree = n-1\n",
    "# confidence = 0.95\n",
    "# t_score = stats.t.ppf((1+confidence)/2,degfree)\n",
    "# margin_of_error = t_score * (stdev / np.sqrt(n))\n",
    "\n",
    "# conf_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "# print(conf_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e254c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_mean = 0\n",
    "# t_statistic, p_value = stats.ttest_1samp(ites_test, pop_mean)\n",
    "# alpha = 0.05\n",
    "\n",
    "# print(f\"T-statistic: {t_statistic}\")\n",
    "# print(f\"P-value: {p_value}\")\n",
    "\n",
    "# if p_value < alpha:\n",
    "#     print(\"Result is statistically significant\")\n",
    "    \n",
    "# else:\n",
    "#     print(\"Result is not significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59144fd5",
   "metadata": {},
   "source": [
    "We can now examine the performance of the model by calling ``metrics``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644e60d",
   "metadata": {},
   "source": [
    "We can also visualise the model's *factual* predicted performance by calling the ``visualise`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c67a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = \"RandomForest\"\n",
    "visualise(predictions_t, predictions_c, y_test_t, y_test_c, machine=machine, target=OUTCOME, intervention=TREATMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c4e25",
   "metadata": {},
   "source": [
    "Also, if we want to visualize the ITES, we can run the following function (``visualise_ites``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_ites(ites_train, machine = machine, intervention = TREATMENT, target = OUTCOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76538fdb",
   "metadata": {},
   "source": [
    "### 3.b Run More Models\n",
    "\n",
    "These models can be run also. Feel free to remove some of the models, but please run at least:\n",
    "\n",
    "- ``RandomForestRegressor()``\n",
    "- ``GradientBoostingRegressor()``\n",
    "- ``LinearRegression()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b530bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lst = [(RandomForestRegressor(),RandomForestRegressor()), (MLPRegressor(), MLPRegressor()), \n",
    "            (GradientBoostingRegressor(), GradientBoostingRegressor()), (DecisionTreeRegressor(), DecisionTreeRegressor()),\n",
    "            (LinearRegression(), LinearRegression()), (Ridge(), Ridge()), (Lasso(), Lasso()),\n",
    "            (AdaBoostRegressor(), AdaBoostRegressor()), (ExtraTreesRegressor(), ExtraTreesRegressor()), \n",
    "             (BaggingRegressor(), BaggingRegressor())]\n",
    "\n",
    "for model1, model2 in model_lst:\n",
    "    print(str(model1))\n",
    "    metrics, predictions_t, predictions_c, y_test_t, y_test_c, ites_test, ites_train, X_test_t, X_test_c, X_train_c, X_train_t = run_model(n_bootstraps = 1, file = FILE, include_propensity = PROPENSITY, outcome=OUTCOME, intervention=TREATMENT, undersampled = UNDERSAMPLE, model0 = model0, model1 = model1, machine = str(model1), num_iter = 1)\n",
    "    #visualise(predictions_t, predictions_c, y_test_t, y_test_c, machine=machine, target=target, intervention=intervention)\n",
    "    visualise_ites(ites_test, machine = str(model1), intervention = TREATMENT, target = OUTCOME)\n",
    "    confidence_interval(data=ites_test)\n",
    "    significance(data=ites_test)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b77a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb097ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadef90",
   "metadata": {},
   "source": [
    "## 3.c IDs for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(pd.concat([y_test_c, y_test_t])).reset_index()\n",
    "vars_test = pd.concat([X_test_t, X_test_c]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.merge(predictions, vars_test, left_index=True, right_index=True)\n",
    "index_df[\"ITEs\"] = index_df['OutcomeT1'] - index_df[\"OutcomeT0\"]\n",
    "\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e356b6",
   "metadata": {},
   "source": [
    "## Part 4. Adaptive Model\n",
    "\n",
    "In this last part, we will predict the treatment effect using an adaptive model. This model was developed by us. As can be seen, there is a bit more coding involved, but the benefit is that it is easier to adapt this model to our preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d8a6e",
   "metadata": {},
   "source": [
    "The first step is to make sure that our model runs on the proper device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61593339",
   "metadata": {},
   "source": [
    "It is useful to have a small function that easily converts arrays to the correct ``torch``-objects: tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1eb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = lambda x: torch.tensor(np.array(x), dtype = torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = f\"data/03-10-2023-Dutch_LTCF_cleaned_data_with_selected_covar_{TREATMENT}-{OUTCOME}.csv\"\n",
    "df = pd.read_csv(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a3401",
   "metadata": {},
   "source": [
    "### Uplift Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = df.drop('OutcomeT1', axis=1)\n",
    "y = df['OutcomeT1']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model on treatment group\n",
    "model_treatment = LogisticRegression()\n",
    "model_treatment.fit(X_train[X_train['treatment'] == 1].drop('treatment', axis=1), y_train[X_train['treatment'] == 1])\n",
    "\n",
    "# Train model on control group\n",
    "model_control = LogisticRegression()\n",
    "model_control.fit(X_train[X_train['treatment'] == 0].drop('treatment', axis=1), y_train[X_train['treatment'] == 0])\n",
    "\n",
    "# Predict probabilities\n",
    "prob_treatment = model_treatment.predict_proba(X_test.drop('treatment', axis=1))[:, 1]\n",
    "prob_control = model_control.predict_proba(X_test.drop('treatment', axis=1))[:, 1]\n",
    "\n",
    "# Calculate uplift\n",
    "uplift = prob_treatment - prob_control\n",
    "\n",
    "# Sorting the individuals by predicted uplift\n",
    "order = np.argsort(uplift)[::-1]\n",
    "sorted_uplift = uplift[order]\n",
    "\n",
    "# Calculating cumulative uplift\n",
    "cumulative_uplift = np.cumsum(sorted_uplift) / len(y_test)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlim(0,100)\n",
    "plt.plot(cumulative_uplift, label='Uplift Curve')\n",
    "plt.xlabel('Proportion Targeted')\n",
    "plt.ylabel('Cumulative Uplift')\n",
    "plt.title('Uplift Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min-max normalisation\n",
    "#X = df.drop(columns = ['treatment', 'OutcomeT1']).columns\n",
    "#df[X] = (df[X] - df[X].min()) / (df[X].max() - df[X].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['treatment', 'OutcomeT1']).columns\n",
    "\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "normalizer.fit(df[X])\n",
    "\n",
    "df[X] = normalizer.fit_transform(df[X])\n",
    "\n",
    "with open(f'storage/normalizer_{TREATMENT}-{OUTCOME}.pkl', 'wb') as f:\n",
    "    pickle.dump(normalizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0436003",
   "metadata": {},
   "source": [
    "### 4 a. Perform Undersampling Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if UNDERSAMPLE:\n",
    "    freq_treated = len(df[df['treatment']==1])\n",
    "    control = df[df['treatment']==0].sample(freq_treated)\n",
    "    treated = df[df['treatment']==1]\n",
    "    df = pd.concat((control, treated))\n",
    "    \n",
    "print(f'DF lenght after undersampling: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db0f23",
   "metadata": {},
   "source": [
    "Because the model is a neural-network based architecture, it is usually helpful to apply min-max normalisation which converts the column values to \\[0,1\\] ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edac5f6",
   "metadata": {},
   "source": [
    "### 4.b Train-Test Splitting\n",
    "\n",
    "In the cell below, we perform train-test split. Note that we also split the train and test data into two groups: a control group and a treated group. Even though we do not explicItely use for train, it will be useful for the (sub-)group evaluation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable setting for treatment\n",
    "t = 'treatment'\n",
    "# select the relevant outcome\n",
    "y = \"OutcomeT1\" \n",
    "# specify test size\n",
    "test_size = 0.2\n",
    "\n",
    "# Split groups into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = [y]), df[['treatment', y]], test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ce86e",
   "metadata": {},
   "source": [
    "### 4.c Propensity Score Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b94b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the propensity score\n",
    "if PROPENSITY:\n",
    "    X_train[\"OutcomeT1\"] = y_train[\"OutcomeT1\"]\n",
    "    X_test[\"OutcomeT1\"] = y_test[\"OutcomeT1\"]\n",
    "    X = X_train.drop(columns = ['treatment']).columns\n",
    "    X = X_test.drop(columns = ['treatment']).columns\n",
    "    ps_model = LogisticRegression(C=1e2, max_iter=10000).fit(X_train[X], y_train['treatment'])\n",
    "    X_train['ps'] = ps_model.predict_proba(X_train[X])[:, 1]\n",
    "    X_test['ps'] = ps_model.predict_proba(X_test[X])[:, 1]\n",
    "    \n",
    "    # ensure that treatment is last column\n",
    "    X_train['treatment_new'] =  X_train['treatment']\n",
    "    X_train = X_train.drop(columns = ['treatment'])\n",
    "    X_train = X_train.rename(columns = {'treatment_new': 'treatment'})\n",
    "    \n",
    "    X_test['treatment_new'] =  X_test['treatment']\n",
    "    X_test = X_test.drop(columns = ['treatment'])\n",
    "    X_test = X_test.rename(columns = {'treatment_new': 'treatment'})\n",
    "    \n",
    "    #X_train = X_train.drop(columns = [\"OutcomeT1\"])\n",
    "else:\n",
    "    X_train[\"OutcomeT1\"] = y_train[\"OutcomeT1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['OutcomeT1', 'treatment']).columns\n",
    "\n",
    "#X_train = X_train.drop(columns = [\"ps\"])\n",
    "\n",
    "# Estimate the average treatment effect (group level)\n",
    "tau_est = doubly_robust(X_train, X=X, T='treatment', Y='OutcomeT1')\n",
    "tau_est = torch.tensor(tau_est, dtype = torch.float32).to(device)\n",
    "print(tau_est)\n",
    "\n",
    "# drop columns\n",
    "X_train = X_train.drop(columns = [\"OutcomeT1\"])\n",
    "\n",
    "if PROPENSITY == True:\n",
    "    X_test = X_test.drop(columns = [\"OutcomeT1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357dffa",
   "metadata": {},
   "source": [
    "We also want to make sure that the data stuctures are in the right format. For this, we use ``to_tensor``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_train[y_train['treatment']==1][y]\n",
    "y_c = y_train[y_train['treatment']==0][y]\n",
    "\n",
    "y_test_t = y_test[y_test['treatment']==1][y]\n",
    "y_test_c = y_test[y_test['treatment']==0][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output to tensors\n",
    "x, y, y_t, y_c, x_test = to_tensor(X_train), to_tensor(y_train), to_tensor(y_t), to_tensor(y_c), to_tensor(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076a548",
   "metadata": {},
   "source": [
    "### 4.d Model Training\n",
    "\n",
    "The next step is to train the actual model. The code below sets some preliminary configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "lr = 0.001\n",
    "epochs = 1000\n",
    "gamma = 2\n",
    "\n",
    "model = TARnetICFR(x.shape[1], 0.01, hidden_dim = 32*4).to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "head_loss = nn.L1Loss() #nn.MSELoss()#nn.L1Loss() #torch.nn.HuberLoss(reduction = 'mean', delta = 1) #nn.MSELoss() # nn.L1Loss() #nn.MSELoss() \n",
    "\n",
    "# initialise optimiser\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "u = len(y_t)  / (len(y_t)  + len(y_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb592f",
   "metadata": {},
   "source": [
    "The code below is the training loop. On each loop, the model passes the data through the models, examines its performance and adjust the weights. Note that this model has four loss components:\n",
    "\n",
    "1. Component 1 (``loss1``) is to loss on the treated segment of the data.\n",
    "2. Component 2 (``loss2``) is to loss on the control segment of the data.\n",
    "3. Component 2 (``loss_cf_3``) is to loss on the counterfactual control segment of the data.\n",
    "4. Component 2 (``loss_cf_4``) is to loss on the counterfactual treated segment of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba813bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss lists\n",
    "loss1_lst, loss2_lst, loss3_lst = [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    output_t, output_c, _ = model(x)\n",
    "    \n",
    "    # Compute total loss and update the model's parameters\n",
    "    loss1, loss2 = head_loss(torch.squeeze(output_t), y_t), head_loss(torch.squeeze(output_c), y_c)\n",
    "    \n",
    "    pred_c_cf = model.forward_treated(x[x[:,-1]==0])\n",
    "    loss_cf_3 = (1 - u) * torch.mean((torch.squeeze(pred_c_cf) - (y_c + tau_est))**2)\n",
    "                 \n",
    "    pred_t_cf = model.forward_control(x[x[:,-1]==1])\n",
    "    loss_cf_4 = u * torch.mean((torch.squeeze(pred_t_cf) - (y_t - tau_est))**2)\n",
    "    \n",
    "    # losses added\n",
    "    loss = loss1 + (loss2) + loss_cf_3 + loss_cf_4 #+ (gamma * loss3)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10000 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # print intermediate results on test\n",
    "        x_test_t = x_test[x_test[:,-1]==1] \n",
    "        x_test_c = x_test[x_test[:,-1]==0] \n",
    "\n",
    "        # # examine intermediate factual test performance\n",
    "        y_t_pred = model.forward_treated(x_test_t).cpu().detach().numpy().reshape(len(x_test_t),)\n",
    "        y_c_pred = model.forward_control(x_test_c).cpu().detach().numpy().reshape(len(x_test_c),)\n",
    "\n",
    "        print(f\"RMSE for factual treated {mean_squared_error(y_t_pred, y_test_t)}\") \n",
    "        print(f\"MAE for factual treated {mean_absolute_error(y_t_pred, y_test_t)}\") \n",
    "        print(f\"RMSE for factual control {mean_squared_error(y_c_pred, y_test_c)}\") \n",
    "        print(f\"MAE for factual treated {mean_absolute_error(y_c_pred, y_test_c)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e36c19",
   "metadata": {},
   "source": [
    "### 4.e Model Evaluation\n",
    "Having trained the model, we can no examine the performance on the test set. We first get the predictions for the treated and control groups. Then we visualise the predicted predicted vs. true values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb28295",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_pred = model.forward_treated(x_test[x_test[:,-1]==1] ).cpu().detach().numpy()\n",
    "y_c_pred = model.forward_control(x_test[x_test[:,-1]==0] ).cpu().detach().numpy()\n",
    "\n",
    "machine = \"TARNet\"\n",
    "visualise(np.squeeze(y_t_pred), np.squeeze(y_c_pred), y_test_t, y_test_c, machine=machine, target=OUTCOME, intervention=TREATMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb4c9b",
   "metadata": {},
   "source": [
    "Next, we want to estimate the model's predictions of the individual treatment effect. We plot this in an ordered fashion (from most beneficial to least beneficial). The blue dots depict patients. On the y-axis, we find the effect size as predicted by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7e756",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# isolate and disconnect predicted values\n",
    "y_c_predt1 = model.forward_treated(x_test_c).cpu().detach().numpy()\n",
    "y_t_predt1 = model.forward_treated(x_test_t).cpu().detach().numpy()\n",
    "y_t_pred = np.concatenate((y_c_predt1, y_t_predt1))\n",
    "\n",
    "# isolate and disconnect predicted values\n",
    "y_c_predt0 = model.forward_control(x_test_c).cpu().detach().numpy() #np.array(y_test_c).reshape(-1,1) #model.forward_control(x_test_c).cpu().detach().numpy()\n",
    "y_t_predt0 = model.forward_control(x_test_t).cpu().detach().numpy()\n",
    "\n",
    "y_c_pred = np.concatenate((y_c_predt0, y_t_predt0))\n",
    "\n",
    "# compute the ites and sort\n",
    "ites = y_t_pred - y_c_pred\n",
    "ites = [i[0] for i in ites]\n",
    "ites = sorted(list(ites))\n",
    "\n",
    "ate_model_est = np.mean(y_t_pred - y_c_pred)\n",
    "\n",
    "print(f\"ATE_est = {np.mean(y_t_pred)} - {np.mean(y_c_pred)} = {ate_model_est}.\")\n",
    "\n",
    "visualise_ites(np.array(ites), machine = machine, intervention = TREATMENT, target = OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f220f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate and disconnect predicted values\n",
    "y_c_predt1 = model.forward_treated(x_test_c).cpu().detach().numpy()\n",
    "\n",
    "# isolate and disconnect predicted values\n",
    "y_c_predt0 = model.forward_control(x_test_c).cpu().detach().numpy() \n",
    "\n",
    "# compute the ites and sort\n",
    "ites = y_c_predt1 - y_c_predt0\n",
    "ites = [i[0] for i in ites]\n",
    "ites = sorted(list(ites))\n",
    "\n",
    "ate_model_est = np.mean(y_c_predt1 - y_c_predt0)\n",
    "\n",
    "print(f\"ATE_est = {np.mean(y_c_predt1)} - {np.mean(y_c_predt0)} = {ate_model_est}.\")\n",
    "\n",
    "visualise_ites(np.array(ites), machine = machine, intervention = TREATMENT, target = OUTCOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0f027",
   "metadata": {},
   "source": [
    "### 4.e Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cde8d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Calculate the baseline performance\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Ensure no gradients are computed\n",
    "    output_t, output_c, _ = model(x)\n",
    "baseline_performance = mean_squared_error(output_t, y_t)\n",
    "print(baseline_performance)\n",
    "\n",
    "# Initialize a list to hold the feature importances\n",
    "feature_importances = []\n",
    "icodes = []\n",
    "meanings = []\n",
    "rank = []\n",
    "\n",
    "collist = X_train.columns\n",
    "\n",
    "# Calculate the importance for each feature\n",
    "for i in range(x.shape[1]):  # Iterate over each feature\n",
    "    # Save the original feature\n",
    "    original_feature = x[:, i].clone()\n",
    "    # Permute the feature\n",
    "    permuted_feature = original_feature[torch.randperm(original_feature.size(0))]\n",
    "    x[:, i] = permuted_feature\n",
    "    \n",
    "    # Calculate performance with the permuted data\n",
    "    with torch.no_grad():\n",
    "        output_t, output_c, _ = model(x)\n",
    "        \n",
    "    permuted_performance_t = mean_squared_error(output_t, y_t)\n",
    "    permuted_performance_c = mean_squared_error(output_c, y_c)\n",
    "    \n",
    "    permuted_performance = permuted_performance_t + permuted_performance_t\n",
    "    \n",
    "    # Calculate the importance as the change in performance\n",
    "    importance = baseline_performance - permuted_performance\n",
    "    feature_importances.append(importance)\n",
    "    \n",
    "    # Restore the original feature\n",
    "    x[:, i] = original_feature\n",
    "    \n",
    "# Rank the features by their importance\n",
    "sorted_features = np.argsort(feature_importances)[::-1]  # Indices of features, sorted by importance\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature importances:\")\n",
    "for i, feature_index in enumerate(sorted_features):\n",
    "    #print(f\"Feature {feature_index}: Importance {feature_importances[feature_index]}\")\n",
    "    icode = collist[feature_index]\n",
    "    icodes.append(icode.lower())\n",
    "    \n",
    "    try:\n",
    "        item = encoding[icode.lower()]\n",
    "        #print(item)\n",
    "        meanings.append(item)\n",
    "    except KeyError:\n",
    "        #print(f'{icode} not found')\n",
    "        meanings.append(f'{icode} not found')\n",
    "    #print(\"==================================================\")\n",
    "    \n",
    "rankings = pd.DataFrame(icodes, columns = ['icodes'])\n",
    "rankings['meanings'] = meanings\n",
    "rankings['importance_values'] = feature_importances\n",
    "\n",
    "rankings = rankings.sort_values(by = 'importance_values')\n",
    "rankings = rankings.reset_index().drop(columns = 'index')\n",
    "rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab57c9",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0daa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "location = 'storage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(f'storage/model_{TREATMENT}-{OUTCOME}.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(f'storage/model_{TREATMENT}-{OUTCOME}.pkl', 'rb') as b:\n",
    "    loaded_model = pickle.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6285d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548704e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
